{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "pd.set_option('display.max_columns', None)\n",
    "os.chdir(\"/Users/Lenovo/\") #set your directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/genuine_accounts_users.csv',\n",
       " 'dataset/fake_followers_users.csv',\n",
       " 'dataset/social_spambots_1_users_.csv',\n",
       " 'dataset/social_spambots_2_users.csv',\n",
       " 'dataset/social_spambots_3_users.csv',\n",
       " 'dataset/traditional_spambots_1_users.csv',\n",
       " 'dataset/traditional_spambots_2_users.csv',\n",
       " 'dataset/traditional_spambots_3_users.csv',\n",
       " 'dataset/traditional_spambots_4_users.csv',\n",
       " 'dataset/rus_users.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR = \"dataset/\"\n",
    "COLUMN_NAMES = [\"isGenuine\", \"statuses_count\", \"followers_count\", \"friends_count\", \"favourites_count\",\n",
    "                \"listed_count\", \"default_profile\", \"geo_enabled\", \"profile_use_background_image\", \"verified\", \"protected\",\"id\"]\n",
    "COLUMN_NAMES_new = [\"isGenuine\", \"statuses_count\", \"followers_count\", \"friends_count\", \"favourites_count\",\n",
    "                \"listed_count\", \"verified\",\"id\"]\n",
    "rus_users = pd.read_csv('dataset/rus_users.csv',na_filter=False)\n",
    "account_files = glob.glob(DIR + 'genuine_accounts_users.csv')\n",
    "account_files.append(DIR + \"fake_followers_users.csv\")\n",
    "account_files.append(DIR + \"social_spambots_1_users_.csv\")\n",
    "account_files.append(DIR + \"social_spambots_2_users.csv\")\n",
    "account_files.append(DIR + \"social_spambots_3_users.csv\")\n",
    "account_files.append(DIR + \"traditional_spambots_1_users.csv\")\n",
    "account_files.append(DIR + \"traditional_spambots_2_users.csv\")\n",
    "account_files.append(DIR + \"traditional_spambots_3_users.csv\")\n",
    "account_files.append(DIR + \"traditional_spambots_4_users.csv\")\n",
    "account_files.append(DIR + \"rus_users.csv\")\n",
    "data = []\n",
    "file_paths = []\n",
    "for file_path in account_files:\n",
    "    account_set = pd.read_csv(file_path, delimiter=',', dtype=str, error_bad_lines=False)\n",
    "    account_set[\"isGenuine\"] = 0\n",
    "    if file_path == \"dataset\\\\genuine_accounts_users.csv\":\n",
    "        account_set[\"isGenuine\"] = 1\n",
    "    data.append(account_set)\n",
    "    file_paths.append(file_path)\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## for Experiment-1 use 1083 accounts for genuine accounts dataset #################################\n",
    "from numpy import loadtxt\n",
    "ids = loadtxt(\"genuine_account_ids.txt\", delimiter=\"\\n\", unpack=False)\n",
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use these for Experiment 1-2\n",
    "\n",
    "ff_y = data[0]['isGenuine']\n",
    "ga_y = data[1]['isGenuine']\n",
    "ss1_y = data[2]['isGenuine']\n",
    "ss2_y = data[3]['isGenuine']\n",
    "ss3_y = data[4]['isGenuine']\n",
    "ts1_y = data[5]['isGenuine']\n",
    "ts2_y = data[6]['isGenuine']\n",
    "ts3_y = data[7]['isGenuine']\n",
    "ts4_y = data[8]['isGenuine']\n",
    "ru_y = data[9]['isGenuine']\n",
    "\n",
    "ff = data[0][COLUMN_NAMES].fillna(value=0)\n",
    "#data[1]['id'] = data[1]['id'].astype(float) #use for Experiment-1 -> 1083 account, commented out for experiment 2-3\n",
    "#data[1] = data[1][data[1]['id'].isin(ids)] #use for Experiment-1 -> 1083 account, commented out for experiment 2-3\n",
    "ga = data[1][COLUMN_NAMES].fillna(value=0)\n",
    "ss1 = data[2][COLUMN_NAMES].fillna(value=0)\n",
    "ss2 = data[3][COLUMN_NAMES].fillna(value=0)\n",
    "ss3 = data[4][COLUMN_NAMES].fillna(value=0)\n",
    "ts1 = data[5][COLUMN_NAMES].fillna(value=0)\n",
    "ts2 = data[6][COLUMN_NAMES].fillna(value=0)\n",
    "ts3 = data[7][COLUMN_NAMES].fillna(value=0)\n",
    "ts4 = data[8][COLUMN_NAMES].fillna(value=0)\n",
    "\n",
    "ru = data[9][COLUMN_NAMES_new].fillna(value=0)\n",
    "ru['default_profile'] = 1\n",
    "ru['geo_enabled'] = 0\n",
    "ru['profile_use_background_image'] = 0\n",
    "ru['protected'] = 0\n",
    "ru['verified'] = ru['verified'].map({'true': int(1), 'false': int(0)})\n",
    "ru['id'] = ru['id'].map(lambda x: str(x))\n",
    "ru = ru.fillna(value=0)\n",
    "data[9] = ru\n",
    "\n",
    "#print(ru)\n",
    "ff = ff.drop('isGenuine', axis=1)\n",
    "ga = ga.drop('isGenuine', axis=1)\n",
    "ss1 = ss1.drop('isGenuine', axis=1)\n",
    "ss2 = ss2.drop('isGenuine', axis=1)\n",
    "ss3 = ss3.drop('isGenuine', axis=1)\n",
    "ts1 = ts1.drop('isGenuine', axis=1)\n",
    "ts2 = ts2.drop('isGenuine', axis=1)\n",
    "ts3 = ts3.drop('isGenuine', axis=1)\n",
    "ts4 = ts4.drop('isGenuine', axis=1)\n",
    "ru = ru.drop('isGenuine', axis=1)\n",
    "dataset_ = pd.DataFrame()\n",
    "for i in range(len(data[:9])):\n",
    "    #if i!=9 and i!=8 and i!=7 and i!=6 and i!=5 and i!=3 and i!=0: #extract the datasets that do not want to use for the experiment\n",
    "    dataset_ = pd.concat([dataset_,data[i][COLUMN_NAMES]],sort=False)\n",
    "dataset_['id'] = dataset_['id'].astype(float)\n",
    "dataset = dataset_.sort_values(by='id')\n",
    "y = dataset[\"isGenuine\"]\n",
    "X = dataset.drop('isGenuine', axis=1)\n",
    "X = X.sort_values(by=['id'])\n",
    "y = y.fillna(value= 0) #for 1 russian bot\n",
    "#X = X.drop('id', axis=1)\n",
    "X = X.fillna(value= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this for experiment 3\n",
    "\n",
    "os.chdir(\"/Users/Lenovo/dataset/\")\n",
    "#use the followings for scenarios that datasets are concatenated \n",
    "#train_dataset1 = pd.read_csv(\"vendorPurchased.csv\", na_filter=False, lineterminator='\\n', sep=',')\n",
    "#train_dataset2 = pd.read_csv(\"verified.csv\", na_filter=False, lineterminator='\\n', sep=',')\n",
    "#train_dataset3 = pd.read_csv(\"politicalBots.csv\", na_filter=False, lineterminator='\\n', sep=',')\n",
    "#train_dataset = pd.concat([train_dataset1,train_dataset2,train_dataset3])\n",
    "train_dataset = pd.read_csv(\"cresciRtbust.csv\", na_filter=False, lineterminator='\\n', sep=',')\n",
    "train_score = train_dataset[['id','name','screen_name','statuses_count','followers_count','friends_count','favourites_count','listed_count','url','lang','time_zone','location','default_profile','default_profile_image','geo_enabled','profile_image_url','profile_banner_url','profile_use_background_image','profile_background_image_url_https','profile_text_color','profile_image_url_https','profile_sidebar_border_color','profile_background_tile','profile_sidebar_fill_color','profile_background_image_url','profile_background_color','profile_link_color','utc_offset','is_translator','follow_request_sent','protected','verified','notifications','description','contributors_enabled','following','created_at']]\n",
    "train_score_y = train_dataset.iloc[:,42:]\n",
    "train_score_y.columns = train_score_y.columns.str.strip() \n",
    "train_score_y = train_score_y['knownBot'].map({1:0,0:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this for experiment 3\n",
    "\n",
    "train_score = train_score[[\"statuses_count\", \"followers_count\", \"friends_count\", \"favourites_count\",\"listed_count\", \"default_profile\", \"geo_enabled\", \"profile_use_background_image\", \"verified\", \"protected\",\"id\"]]\n",
    "train_score = train_score.fillna(value=0)\n",
    "train_score['default_profile'] = train_score['default_profile'].map({True: 1, False: 0})\n",
    "train_score['geo_enabled'] = train_score['geo_enabled'].map({True: 1, False: 0})\n",
    "train_score['profile_use_background_image'] = train_score['profile_use_background_image'].map({True: 1, False: 0})\n",
    "train_score['verified'] = train_score['verified'].map({True: 1, False: 0})\n",
    "train_score['protected'] = train_score['protected'].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = train_score\n",
    "y = train_score_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sme = SMOTEENN(smote=SMOTE(k_neighbors=10))\n",
    "train_score, train_score_y = sme.fit_resample(X, y)\n",
    "\n",
    "gbc = GradientBoostingClassifier(loss='exponential')\n",
    "abc = AdaBoostClassifier(n_estimators=1000, learning_rate=0.5, base_estimator=gbc)\n",
    "\n",
    "model = abc.fit(train_score, train_score_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9880184331797235\n",
      "Precision Score 0.8966942148760331\n",
      "Recall Score 0.9954128440366973\n",
      "F1 Score 0.9434782608695652\n",
      "AUC: 0.9913027334937585\n",
      "MCC: 0.9383959652592238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1927,   25],\n",
       "       [   1,  217]], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision Score\", precision_score(y_test, y_pred))\n",
    "print(\"Recall Score\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score\", f1_score(y_test, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"MCC:\", matthews_corrcoef(y_test, y_pred))\n",
    "conf = mt.confusion_matrix(y_test,y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT 2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/Lenovo/dataset/\")\n",
    "#use the followings for scenarios that datasets are concatenated \n",
    "#test_dataset1 = pd.read_csv(\"vendorPurchased.csv\", na_filter=False, lineterminator='\\n', sep=',')\n",
    "#test_dataset2 = pd.read_csv(\"verified.csv\", na_filter=False, lineterminator='\\n', sep=',')\n",
    "#test_dataset3 = pd.read_csv(\"politicalBots.csv\", na_filter=False, lineterminator='\\n', sep=',')\n",
    "#test_dataset = pd.concat([test_dataset1,test_dataset2,test_dataset3])\n",
    "test_dataset = pd.read_csv(\"gilani.csv\", na_filter=False, lineterminator='\\n', sep=',')\n",
    "test_score = test_dataset[['name','screen_name','statuses_count','followers_count','friends_count','favourites_count','listed_count','url','lang','time_zone','location','default_profile','default_profile_image','geo_enabled','profile_image_url','profile_banner_url','profile_use_background_image','profile_background_image_url_https','profile_text_color','profile_image_url_https','profile_sidebar_border_color','profile_background_tile','profile_sidebar_fill_color','profile_background_image_url','profile_background_color','profile_link_color','utc_offset','is_translator','follow_request_sent','protected','verified','notifications','description','contributors_enabled','following','created_at']]\n",
    "test_score_y = test_dataset.iloc[:,42:]\n",
    "test_score_y.columns = test_score_y.columns.str.strip() \n",
    "test_score_y = test_score_y['knownBot'].map({1:0,0:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_score = test_score[[\"statuses_count\", \"followers_count\", \"friends_count\", \"favourites_count\",\"listed_count\", \"default_profile\", \"geo_enabled\", \"profile_use_background_image\", \"verified\", \"protected\"]]\n",
    "test_score = test_score.fillna(value=0)\n",
    "test_score['default_profile'] = test_score['default_profile'].map({True: 1, False: 0})\n",
    "test_score['geo_enabled'] = test_score['geo_enabled'].map({True: 1, False: 0})\n",
    "test_score['profile_use_background_image'] = test_score['profile_use_background_image'].map({True: 1, False: 0})\n",
    "test_score['verified'] = test_score['verified'].map({True: 1, False: 0})\n",
    "test_score['protected'] = test_score['protected'].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "X_train = X.drop(columns='id')\n",
    "y_train = y\n",
    "X_test = test_score\n",
    "y_test = test_score_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sme = SMOTEENN(smote=SMOTE(k_neighbors=10))\n",
    "X_train, y_train = sme.fit_resample(X_train, y_train)\n",
    "\n",
    "gbc = GradientBoostingClassifier(loss='exponential')\n",
    "abc = AdaBoostClassifier(n_estimators=1000, learning_rate=0.5, base_estimator=gbc)\n",
    "\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4905356423681031\n",
      "Precision Score 0.5318204242723237\n",
      "Recall Score 0.7733142037302726\n",
      "F1 Score 0.6302250803858521\n",
      "ROC/AUC Score 0.4509362570533824\n"
     ]
    }
   ],
   "source": [
    "# Accuracy: 0.988865692414753\n",
    "# Precision Score 0.9744318181818182\n",
    "# Recall Score 0.98\n",
    "# F1 Score 0.9772079772079771\n",
    "# ROC/AUC Score 0.9984616901038245\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "y_scores = model.decision_function(X_test)\n",
    "print(\"Precision Score\", precision_score(y_test, y_pred))\n",
    "print(\"Recall Score\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score\", f1_score(y_test, y_pred))\n",
    "print(\"ROC/AUC Score\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
